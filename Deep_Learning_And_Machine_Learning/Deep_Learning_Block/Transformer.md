
> [!info] 
> 在学习Transformer前，你需要学习 [⭐Attention](Deep_Learning_And_Machine_Learning/Deep_Learning_Block/⭐Attention.md)



Transformer 是Seq2Seq model，由Encoder和Decoder组成
![300](Deep_Learning_And_Machine_Learning/Deep_Learning_Block/attachments/Pasted%20image%2020230316160103.png)

# Encoder
这里贴的是原文Encoder的架构
![Pasted image 20230316162635](Deep_Learning_And_Machine_Learning/Deep_Learning_Block/attachments/Pasted%20image%2020230316162635.png)

![Pasted image 20230316162642](Deep_Learning_And_Machine_Learning/Deep_Learning_Block/attachments/Pasted%20image%2020230316162642.png)